[cloudera@quickstart ~]$ hdfs dfs -ls

[cloudera@quickstart ~]$ hdfs dfs -mkdir sales

[cloudera@quickstart ~]$ hdfs dfs -ls sales/

[cloudera@quickstart ~]$ hdfs dfs -put /tmp/hive_assignment/sales_order_data.csv sales/

[cloudera@quickstart ~]$ hdfs dfs -ls sales/
Found 1 items
-rw-r--r--   1 cloudera cloudera     360235 2023-04-13 06:06 sales/sales_order_data.csv

[cloudera@quickstart ~]$ hive

Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties
WARNING: Hive CLI is deprecated and migration to Beeline is recommended.

hive> create table sales_order_csv
    > (
    > ordernumber int,
    > quantityordered int,
    > priceeach float,
    > orderlinenumber int,
    > sales float,
    > status string,
    > qtr_id int,
    > month_id int,
    > year_id int,
    > productline string,
    > msrp int,
    > productcode string,
    > phone string, 
    > city string,
    > state string,
    > postalcode string,
    > countrycode string,
    > territory string,
    > contactlastname string,
    > contactfirstname string,
    > dealsize string
    > ) row format delimited
    > fields terminated by','
    > tblproperties("skip.header.line.count"="1");
OK
Time taken: 2.23 seconds

hive> load data inpath 'sales/' into table sales_order_csv;
Loading data to table default.sales_order_csv
Table default.sales_order_csv stats: [numFiles=1, totalSize=360235]
OK
Time taken: 1.864 seconds

hive> set hive.cli.print.header=true;

hive> select * from sales_order_csv limit 3;
OK
sales_order_csv.ordernumber	sales_order_csv.quantityordered	sales_order_csv.priceeach	sales_order_csv.orderlinenumber	sales_order_csv.sales	sales_order_csv.status	sales_order_csv.qtr_id	sales_order_csv.month_id	sales_order_csv.year_id	sales_order_csv.productline	sales_order_csv.msrp	sales_order_csv.productcode	sales_order_csv.phone	sales_order_csv.city	sales_order_csv.state	sales_order_csv.postalcode	sales_order_csv.countrycode	sales_order_csv.territory	sales_order_csv.contactlastname	sales_order_csv.contactfirstname	sales_order_csv.dealsize
10107	30	95.7	2	2871.0	Shipped	1	2	2003	Motorcycles	95	S10_1678	2125557818	NYC	NY	10022	USA	NA	Yu	Kwai	Small
10121	34	81.35	5	2765.9	Shipped	2	5	2003	Motorcycles	95	S10_1678	26.47.1555	Reims		51100	France	EMEA	Henriot	Paul	Small
10134	41	94.74	2	3884.34	Shipped	3	7	2003	Motorcycles	95	S10_1678	+33 1 46 62 7555	Paris75508	France	EMEA	Da Cunha	Daniel	Medium
Time taken: 1.038 seconds, Fetched: 3 row(s)


hive> create table sales_order_orc
    >     (
    >     ordernumber int,
    >     quantityordered int,
    >     priceeach float,
    >     orderlinenumber int,
    >     sales float,
    >     status string,
    >     qtr_id int,
    >     month_id int,
    >     year_id int,
    >     productline string,
    >     msrp int,
    >     productcode string,
    >     phone string, 
    >     city string,
    >     state string,
    >     postalcode string,
    >     countrycode string,
    >     territory string,
    >     contactlastname string,
    >     contactfirstname string,
    >     dealsize string
    >     ) stored as orc;
OK
Time taken: 0.328 seconds



select * from sales_order_orc limit 2;
OK
sales_order_orc.ordernumber	sales_order_orc.quantityordered	sales_order_orc.priceeach	sales_order_orc.orderlinenumber	sales_order_orc.sales	sales_order_orc.status	sales_order_orc.qtr_id	sales_order_orc.month_id	sales_order_orc.year_id	sales_order_orc.productline	sales_order_orc.msrp	sales_order_orc.productcode	sales_order_orc.phone	sales_order_orc.city	sales_order_orc.state	sales_order_orc.postalcode	sales_order_orc.countrycode	sales_order_orc.territory	sales_order_orc.contactlastname	sales_order_orc.contactfirstname	sales_order_orc.dealsize
10107	30	95.7	2	2871.0	Shipped	1	2	2003	Motorcycles	95	S10_1678	2125557818	NYC	NY	10022	USA	NA	Yu	Kwai	Small
10121	34	81.35	5	2765.9	Shipped	2	5	2003	Motorcycles	95	S10_1678	26.47.1555	Reims		51100	France	EMEA	Henriot	Paul	Small
Time taken: 0.128 seconds, Fetched: 2 row(s)



hive> from sales_order_csv insert overwrite table sales_order_orc select *;
Query ID = cloudera_20230420004040_ecf4ada3-5785-474e-809a-280444501252
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1681975508378_0001, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1681975508378_0001/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1681975508378_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2023-04-20 00:41:09,459 Stage-1 map = 0%,  reduce = 0%
2023-04-20 00:41:21,492 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.25 sec
MapReduce Total cumulative CPU time: 5 seconds 250 msec
Ended Job = job_1681975508378_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to: hdfs://quickstart.cloudera:8020/user/hive/warehouse/sales_order_orc/.hive-staging_hive_2023-04-20_00-40-50_150_5588903737427154606-1/-ext-10000
Loading data to table default.sales_order_orc
Table default.sales_order_orc stats: [numFiles=1, numRows=2823, totalSize=37548, rawDataSize=3153291]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 5.25 sec   HDFS Read: 367232 HDFS Write: 37634 SUCCESS
Total MapReduce CPU Time Spent: 5 seconds 250 msec
OK
sales_order_csv.ordernumber	sales_order_csv.quantityordered	sales_order_csv.priceeach	sales_order_csv.orderlinenumber	sales_order_csv.sales	sales_order_csv.status	sales_order_csv.qtr_id	sales_order_csv.month_id	sales_order_csv.year_id	sales_order_csv.productline	sales_order_csv.msrp	sales_order_csv.productcode	sales_order_csv.phone	sales_order_csv.city	sales_order_csv.state	sales_order_csv.postalcode	sales_order_csv.countrycode	sales_order_csv.territory	sales_order_csv.contactlastname	sales_order_csv.contactfirstname	sales_order_csv.dealsize
Time taken: 33.208 seconds


######### Queries 


1) calculate total sales per year --------------------------------------------------------------------------------------------------------------------

hive> select year_id as year, sum(sales) as sales_per_year from sales_order_orc group by year_id;

Query ID = cloudera_20230413070404_bed1281c-705a-411a-9a13-7aad38a3d066
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1681389328338_0002, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1681389328338_0002/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1681389328338_0002
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-04-13 07:04:41,141 Stage-1 map = 0%,  reduce = 0%
2023-04-13 07:05:05,997 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 6.25 sec
2023-04-13 07:05:19,000 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 9.93 sec
MapReduce Total cumulative CPU time: 9 seconds 930 msec
Ended Job = job_1681389328338_0002
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 9.93 sec   HDFS Read: 36831 HDFS Write: 70 SUCCESS
Total MapReduce CPU Time Spent: 9 seconds 930 msec
OK
year	sales_per_year
2003	3516979.547241211
2004	4724162.593383789
2005	1791486.7086791992
Time taken: 56.693 seconds, Fetched: 3 row(s)


2) Find a product for which max orders were placed --------------------------------------------------------------------------------------------------------------

hive> select productcode from(select productcode, count(ordernumber) as total_orders from sales_order_orc group by productcode order by total_orders desc limit 1)tab;

Query ID = cloudera_20230413091010_b0e7e7b9-b5ea-4b50-ba7c-0842c8b060b2
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1681389328338_0003, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1681389328338_0003/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1681389328338_0003
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-04-13 09:10:59,943 Stage-1 map = 0%,  reduce = 0%
2023-04-13 09:11:17,873 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.48 sec
2023-04-13 09:11:29,839 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 7.48 sec
MapReduce Total cumulative CPU time: 7 seconds 480 msec
Ended Job = job_1681389328338_0003
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1681389328338_0004, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1681389328338_0004/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1681389328338_0004
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2023-04-13 09:11:46,823 Stage-2 map = 0%,  reduce = 0%
2023-04-13 09:12:05,647 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.78 sec
2023-04-13 09:12:17,550 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.51 sec
MapReduce Total cumulative CPU time: 6 seconds 510 msec
Ended Job = job_1681389328338_0004
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 7.48 sec   HDFS Read: 28852 HDFS Write: 3071 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.51 sec   HDFS Read: 8101 HDFS Write: 9 SUCCESS
Total MapReduce CPU Time Spent: 13 seconds 990 msec
OK
productcode
S18_3232
Time taken: 96.011 seconds, Fetched: 1 row(s)



3) calculate total sale for each quarter ---------------------------------------------------------------------------------------------------------------------


hive> select qtr_id as quarter, sum(sales) as total_sale from sales_order_orc group by qtr_id;

Query ID = cloudera_20230420031010_b048000e-359e-422a-8f61-34ffce94aede
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1681975508378_0002, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1681975508378_0002/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1681975508378_0002
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-04-20 03:10:33,556 Stage-1 map = 0%,  reduce = 0%
2023-04-20 03:10:43,403 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.07 sec
2023-04-20 03:10:54,313 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.7 sec
MapReduce Total cumulative CPU time: 6 seconds 700 msec
Ended Job = job_1681975508378_0002
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.7 sec   HDFS Read: 36979 HDFS Write: 81 SUCCESS
Total MapReduce CPU Time Spent: 6 seconds 700 msec
OK
quarter	total_sale
1	2350817.726501465
2	2048120.3029174805
3	1758910.808959961
4	3874780.010925293
Time taken: 36.47 seconds, Fetched: 4 row(s)



4) In which quarter the sale was minimum ------------------------------------------------------------------------------------------------------------------------------------

hive> select qtr_id as quarter_with_min_sale, total_sale from(select qtr_id, sum(sales) as total_sale from sales_order_orc group by qtr_id order by total_sale limit 1)tab;

Query ID = cloudera_20230420035858_3109ddaa-cbd8-4c48-a52c-290724eac892
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1681975508378_0025, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1681975508378_0025/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1681975508378_0025
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-04-20 03:58:20,806 Stage-1 map = 0%,  reduce = 0%
2023-04-20 03:58:30,509 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.88 sec
2023-04-20 03:58:42,441 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.24 sec
MapReduce Total cumulative CPU time: 6 seconds 240 msec
Ended Job = job_1681975508378_0025
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1681975508378_0026, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1681975508378_0026/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1681975508378_0026
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2023-04-20 03:58:55,035 Stage-2 map = 0%,  reduce = 0%
2023-04-20 03:59:04,771 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.28 sec
2023-04-20 03:59:15,556 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.83 sec
MapReduce Total cumulative CPU time: 5 seconds 830 msec
Ended Job = job_1681975508378_0026
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.24 sec   HDFS Read: 36169 HDFS Write: 200 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.83 sec   HDFS Read: 5234 HDFS Write: 20 SUCCESS
Total MapReduce CPU Time Spent: 12 seconds 70 msec
OK
3	1758910.808959961
Time taken: 68.866 seconds, Fetched: 1 row(s)



5) In which country sales was maximum and in which country sales was minimum ----------------------------------------------------------------------------------------------------

hive> select min(case when min_sale=1 then countrycode end) as minimum_sale_country, min(case when max_sale=1 then countrycode end) as max_sale_country from (select countrycode, sum(sales) as total_sale, row_number() over(order by sum(sales)) as min_sale , row_number() over(order by sum(sales)desc) as max_sale from sales_order_orc group by countrycode)tab;

Query ID = cloudera_20230424122525_dee0ae01-b94f-4c20-9cc2-c8bd7a562f01
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1682359045390_0010, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1682359045390_0010/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1682359045390_0010
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-04-24 12:25:52,102 Stage-1 map = 0%,  reduce = 0%
2023-04-24 12:26:01,770 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.1 sec
2023-04-24 12:26:13,670 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.63 sec
MapReduce Total cumulative CPU time: 6 seconds 630 msec
Ended Job = job_1682359045390_0010
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1682359045390_0011, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1682359045390_0011/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1682359045390_0011
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2023-04-24 12:26:28,258 Stage-2 map = 0%,  reduce = 0%
2023-04-24 12:26:37,901 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.3 sec
2023-04-24 12:26:49,801 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.79 sec
MapReduce Total cumulative CPU time: 6 seconds 790 msec
Ended Job = job_1682359045390_0011
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1682359045390_0012, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1682359045390_0012/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1682359045390_0012
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2023-04-24 12:27:06,485 Stage-3 map = 0%,  reduce = 0%
2023-04-24 12:27:16,257 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.2 sec
2023-04-24 12:27:29,292 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 6.63 sec
MapReduce Total cumulative CPU time: 6 seconds 630 msec
Ended Job = job_1682359045390_0012
Launching Job 4 out of 4
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1682359045390_0013, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1682359045390_0013/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1682359045390_0013
Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1
2023-04-24 12:27:44,282 Stage-4 map = 0%,  reduce = 0%
2023-04-24 12:27:54,034 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 2.27 sec
2023-04-24 12:28:04,934 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 5.8 sec
MapReduce Total cumulative CPU time: 5 seconds 800 msec
Ended Job = job_1682359045390_0013
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.63 sec   HDFS Read: 37084 HDFS Write: 716 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.79 sec   HDFS Read: 6825 HDFS Write: 735 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 6.63 sec   HDFS Read: 8497 HDFS Write: 125 SUCCESS
Stage-Stage-4: Map: 1  Reduce: 1   Cumulative CPU: 5.8 sec   HDFS Read: 5200 HDFS Write: 12 SUCCESS
Total MapReduce CPU Time Spent: 25 seconds 850 msec
OK
minimum_sale_country	max_sale_country
Ireland	USA
Time taken: 147.03 seconds, Fetched: 1 row(s)



6) calculate quarterly sales for each city --------------------------------------------------------------------------------------------------------------------


hive> select city, qtr_id as quarter, sum(sales) as quarterly_sale from sales_order_orc group by city, qtr_id;

Query ID = cloudera_20230420053939_36c10370-54b2-4147-8bb2-b4a28fb5b1b0
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1681975508378_0031, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1681975508378_0031/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1681975508378_0031
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-04-20 05:39:42,707 Stage-1 map = 0%,  reduce = 0%
2023-04-20 05:39:53,565 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.11 sec
2023-04-20 05:40:04,478 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.83 sec
MapReduce Total cumulative CPU time: 6 seconds 830 msec
Ended Job = job_1681975508378_0031
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.83 sec   HDFS Read: 39073 HDFS Write: 5283 SUCCESS
Total MapReduce CPU Time Spent: 6 seconds 830 msec
OK
Aaarhus	4	100595.5498046875
Allentown	2	6166.7998046875
Allentown	3	71930.61041259766
Allentown	4	44040.729736328125
Barcelona	2	4219.2001953125
Barcelona	4	74192.66003417969
Bergamo	1	56181.320068359375
Bergamo	4	81774.40008544922
Bergen	3	16363.099975585938
Bergen	4	95277.17993164062
Boras	1	31606.72021484375
Boras	3	53941.68981933594
Boras	4	48710.92053222656
Boston	2	74994.240234375
Boston	3	15344.640014648438
Boston	4	63730.7802734375
Brickhaven	1	31474.7802734375
Brickhaven	2	7277.35009765625
Brickhaven	3	114974.53967285156
Brickhaven	4	11528.52978515625
Bridgewater	2	75778.99060058594
Bridgewater	4	26115.800537109375
Brisbane	1	16118.479858398438
Brisbane	3	34100.030029296875
Bruxelles	1	18800.089721679688
Bruxelles	2	8411.949829101562
Bruxelles	3	47760.479736328125
Burbank	1	37850.07958984375
Burbank	4	8234.559936523438
Burlingame	1	13529.570190429688
Burlingame	3	42031.83020019531
Burlingame	4	65221.67004394531
Cambridge	1	21782.699951171875
Cambridge	2	14380.920043945312
Cambridge	3	48828.71942138672
Cambridge	4	54251.659912109375
Charleroi	1	16628.16015625
Charleroi	2	1711.260009765625
Charleroi	3	1637.199951171875
Charleroi	4	13463.480224609375
Chatswood	2	43971.429931640625
Chatswood	3	69694.40002441406
Chatswood	4	37905.14990234375
Cowes	1	26906.68017578125
Cowes	4	51334.15966796875
Dublin	1	38784.470458984375
Dublin	3	18971.959838867188
Espoo	1	51373.49072265625
Espoo	2	31018.230102539062
Espoo	3	31569.430053710938
Frankfurt	1	48698.82922363281
Frankfurt	4	36472.76025390625
Gensve	1	50432.549560546875
Gensve	3	67281.00903320312
Glen Waverly	2	14378.089965820312
Glen Waverly	3	12334.819580078125
Glen Waverly	4	37878.54992675781
Glendale	1	3987.199951171875
Glendale	2	20350.949768066406
Glendale	3	7600.1201171875
Glendale	4	34485.49987792969
Graz	1	8775.159912109375
Graz	4	43488.740234375
Helsinki	1	26422.819458007812
Helsinki	3	42744.0595703125
Helsinki	4	42083.499755859375
Kobenhavn	1	58871.110107421875
Kobenhavn	2	62091.880615234375
Kobenhavn	4	24078.610107421875
Koln	4	100306.58020019531
Las Vegas	2	33847.61975097656
Las Vegas	3	34453.84973144531
Las Vegas	4	14449.609741210938
Lille	1	20178.1298828125
Lille	4	48874.28088378906
Liverpool	2	91211.0595703125
Liverpool	4	26797.210083007812
London	1	8477.219970703125
London	2	32376.29052734375
London	4	83970.029296875
Los Angeles	1	23889.320068359375
Los Angeles	4	24159.14013671875
Lule	1	9748.999755859375
Lule	4	66005.8798828125
Lyon	1	101339.13977050781
Lyon	4	41535.11022949219
Madrid	1	357668.4899291992
Madrid	2	339588.0513305664
Madrid	3	69714.09008789062
Madrid	4	315580.80963134766
Makati City	1	55245.02014160156
Makati City	4	38770.71032714844
Manchester	1	51017.919860839844
Manchester	4	106789.88977050781
Marseille	1	2317.43994140625
Marseille	2	52481.840087890625
Marseille	4	20136.859985351562
Melbourne	1	49637.57067871094
Melbourne	2	60135.84033203125
Melbourne	4	91221.99914550781
Minato-ku	1	38191.38977050781
Minato-ku	2	26482.700256347656
Minato-ku	4	55888.65026855469
Montreal	2	58257.50012207031
Montreal	4	15947.290405273438
Munich	3	34993.92004394531
NYC	1	32647.809814453125
NYC	2	165100.33947753906
NYC	3	63027.92004394531
NYC	4	300011.6999511719
Nantes	1	59617.39978027344
Nantes	2	60344.990173339844
Nantes	3	61310.880126953125
Nantes	4	23031.589599609375
Nashua	1	12133.25
Nashua	4	119552.04949951172
New Bedford	1	48578.95935058594
New Bedford	3	45738.38952636719
New Bedford	4	113557.509765625
New Haven	2	36973.309814453125
New Haven	4	42498.760498046875
Newark	1	8722.1201171875
Newark	2	74506.06909179688
North Sydney	1	65012.41955566406
North Sydney	3	47191.76013183594
North Sydney	4	41791.949462890625
Osaka	1	50490.64013671875
Osaka	2	17114.43017578125
Oslo	3	34145.47021484375
Oslo	4	45078.759765625
Oulu	1	49055.40026855469
Oulu	2	17813.40008544922
Oulu	3	37501.580322265625
Paris	1	71494.17944335938
Paris	2	80215.4203491211
Paris	3	27798.480102539062
Paris	4	89436.60034179688
Pasadena	1	44273.359436035156
Pasadena	3	55776.119873046875
Pasadena	4	4512.47998046875
Philadelphia	1	27398.820434570312
Philadelphia	2	7287.240234375
Philadelphia	4	116503.07043457031
Reggio Emilia	2	41509.94006347656
Reggio Emilia	3	56421.650390625
Reggio Emilia	4	44669.740478515625
Reims	1	52029.07043457031
Reims	2	18971.959716796875
Reims	3	15146.31982421875
Reims	4	48895.59014892578
Salzburg	2	98104.24005126953
Salzburg	3	6693.2802734375
Salzburg	4	45001.10986328125
San Diego	1	87489.23010253906
San Francisco	1	72899.19995117188
San Francisco	4	151459.4805908203
San Jose	2	160010.27026367188
San Rafael	1	267315.2586669922
San Rafael	2	7261.75
San Rafael	3	216297.40063476562
San Rafael	4	163983.64880371094
Sevilla	4	54723.621154785156
Singapore	1	28395.18994140625
Singapore	2	92033.77014160156
Singapore	3	90250.07995605469
Singapore	4	77809.37023925781
South Brisbane	1	21730.029907226562
South Brisbane	3	10640.290161132812
South Brisbane	4	27098.800048828125
Stavern	1	54701.999755859375
Stavern	4	61897.19006347656
Strasbourg	2	80438.47985839844
Torino	3	94117.25988769531
Toulouse	1	15139.1201171875
Toulouse	3	17251.08056640625
Toulouse	4	38098.240234375
Tsawassen	2	31302.500244140625
Tsawassen	3	43332.349609375
Vancouver	4	75238.91955566406
Versailles	1	5759.419921875
Versailles	4	59074.90026855469
White Plains	4	85555.98962402344
Time taken: 34.651 seconds, Fetched: 182 row(s)



7)  Find a month for each year in which maximum number of quantities were sold  ----------------------------------------------------------------------------------------


hive> select year, month from (select year_id as year, month_id as month, sum(quantityordered) as total_sum, dense_rank() over(partition by year_id order by sum(quantityordered) desc) as rank from sales_order_orc group by year_id, month_id)tab where rank=1;

Query ID = cloudera_20230424115454_5a1feae5-8045-4412-ab9c-e3277a07ec60
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1682359045390_0005, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1682359045390_0005/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1682359045390_0005
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-04-24 11:54:38,441 Stage-1 map = 0%,  reduce = 0%
2023-04-24 11:54:49,412 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.98 sec
2023-04-24 11:55:00,199 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.32 sec
MapReduce Total cumulative CPU time: 6 seconds 320 msec
Ended Job = job_1682359045390_0005
Launching Job 2 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1682359045390_0006, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1682359045390_0006/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1682359045390_0006
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2023-04-24 11:55:12,687 Stage-2 map = 0%,  reduce = 0%
2023-04-24 11:55:23,439 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.24 sec
2023-04-24 11:55:34,221 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.81 sec
MapReduce Total cumulative CPU time: 6 seconds 810 msec
Ended Job = job_1682359045390_0006
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.32 sec   HDFS Read: 29543 HDFS Write: 792 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.81 sec   HDFS Read: 8701 HDFS Write: 23 SUCCESS
Total MapReduce CPU Time Spent: 13 seconds 130 msec
OK
year	month
2003	11
2004	11
2005	5
Time taken: 69.522 seconds, Fetched: 3 row(s)


------------------------------------------------------------------------------------------------------------------------------------


